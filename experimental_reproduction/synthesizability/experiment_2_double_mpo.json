{
  "logging": {
    "logging_path": "<path to saturn directory>/experimental_reproduction/synthesizability/exp_2_double_mpo_log.log",
    "model_checkpoints_dir": "<path to saturn directory>/experimental_reproduction/synthesizability/exp_2_double_mpo_checkpoints/"
  },
  "oracle": {
    "budget": 1000,
    "allow_oracle_repeats": false,
    "aggregator": "product",
    "components": [
      {
        "name": "aizynthfinder",
        "weight": 1,
        "preliminary_check": false,
        "specific_parameters": {
          "env_name": "aizynth-env",
          "config_path": "<path to saturn directory>/experimental_reproduction/synthesizability/aizynthfinder/config.yml",
          "optimize_path_length": false,
          "parallelize": true,
          "max_workers": 4
        },
        "reward_shaping_function_parameters": {
          "transformation_function": "binary"
        }
      },
      {
        "name": "quickvina2_gpu",
        "weight": 1,
        "preliminary_check": false,
        "specific_parameters": {
          "binary": "<path to saturn directory>/experimental_reproduction/synthesizability/Vina-GPU-2.1/QuickVina2-GPU-2.1/QuickVina2-GPU-2-1",
          "force_field": "uff",
          "receptor": "<path to saturn directory>/experimental_reproduction/synthesizability/7uvu-2-monomers-pdbfixer.pdbqt",
          "reference_ligand": "<path to saturn directory>/experimental_reproduction/synthesizability/7uvu-reference.pdb",
          "thread": 8000,
          "results_dir": "<path to saturn directory>/experimental_reproduction/synthesizability/exp_2_double_mpo_docking_results"
        },
        "reward_shaping_function_parameters": {
          "transformation_function": "reverse_sigmoid",
          "parameters": {
            "low": -16,
            "high": 0,
            "k": 0.15
          }
        }
      }
    ]
  },
  "goal_directed_generation": {
    "reinforcement_learning": {
      "prior": "<path to saturn directory>/experimental_reproduction/checkpoint_models/chembl-33-mamba-epoch-18.prior",
      "agent": "<path to saturn directory>/experimental_reproduction/checkpoint_models/chembl-33-mamba-epoch-18.prior",
      "batch_size": 16,
      "learning_rate": 0.0001,
      "sigma": 128.0,
      "augmented_memory": true,
      "augmentation_rounds": 10,
      "selective_memory_purge": true
    },
    "experience_replay": {
      "memory_size": 100,
      "sample_size": 10,
      "smiles": []
    },
    "diversity_filter": {
      "name": "IdenticalMurckoScaffold",
      "bucket_size": 10
    },
    "hallucinated_memory": {
      "execute_hallucinated_memory": false,
      "hallucination_method": "ga",
      "num_hallucinations": 100,
      "num_selected": 5,
      "selection_criterion": "random"
    },
    "beam_enumeration": {
      "execute_beam_enumeration": false,
      "beam_k": 2,
      "beam_steps": 18,
      "substructure_type": "structure",
      "structure_min_size": 15,
      "pool_size": 4,
      "pool_saving_frequency": 1000,
      "patience": 5,
      "token_sampling_method": "topk",
      "filter_patience_limit": 100000
    }
  },
  "distribution_learning": {
    "parameters": {
      "agent": "<unused>",
      "training_steps": 20,
      "batch_size": 512,
      "learning_rate": 0.0001,
      "training_dataset_path": "cleaned-chembl-33.smi",
      "train_with_randomization": true,
      "transfer_learning": false
    }
  },
  "running_mode": "goal_directed_generation",
  "model_architecture": "mamba",
  "device": "cuda",
  "seed": 0
}
